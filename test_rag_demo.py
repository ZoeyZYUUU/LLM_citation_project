from dotenv import load_dotenv
load_dotenv()

from langchain_cohere import CohereEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain.docstore.document import Document
from models.cohere_llm import ask_cohere  # âœ… Cohere å›ç­”å‡½æ•°

# 1. æ¨¡æ‹Ÿæ–‡æ¡£ï¼ˆå¯æ›¿æ¢ä¸ºçœŸå®æ–‡æ¡£ï¼‰
docs = [
    Document(page_content="Retrieval-augmented generation enhances large language models with document grounding."),
    Document(page_content="LangChain is a framework for chaining together LLM calls and tools."),
    Document(page_content="Cohere provides large language models and embedding services for developers.")
]

# 2. æ–‡æœ¬åˆ‡å—
splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=10)
split_docs = splitter.split_documents(docs)

# 3. å‘é‡åµŒå…¥ + FAISS æ„å»º
embedding = CohereEmbeddings(model="embed-english-v3.0")
db = FAISS.from_documents(split_docs, embedding)

# 4. æ£€ç´¢ç›¸å…³æ–‡æ¡£
query = "What is LangChain?"
retrieved_docs = db.similarity_search(query, k=2)
context = "\n".join([doc.page_content for doc in retrieved_docs])

# 5. æ‹¼æ¥ Prompt
prompt = f"""You are a helpful assistant. Use the context below to answer the question.

Context:
{context}

Question: {query}
Answer:"""

# 6. ç”Ÿæˆå›ç­”
response = ask_cohere(prompt)
print("ğŸ“˜ Cohere Answer:\n", response)

